{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_KW73O2e3dw",
    "outputId": "fa5fd2b3-e2de-491b-ee1c-405317ba7ebc"
   },
   "outputs": [],
   "source": [
    "# Required module for Spark initialization\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XbWNf1Te5fM"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark_session = SparkSession.builder.appName(\"SparkSQLExample\").getOrCreate()\n",
    "\n",
    "# Local file path (corrected)\n",
    "local_csv_file = \"file:///C:/Users/adity/Downloads/home_sales_revised.csv\"\n",
    "\n",
    "# Reading the local CSV file into a DataFrame\n",
    "df_home_sales = spark_session.read.csv(local_csv_file, header=True, inferSchema=True)\n",
    "df_home_sales.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wOJqxG_RPSwp",
    "outputId": "7857ef9f-5b04-405d-f5aa-e535dfe7870c"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Corrected URL of the CSV file\n",
    "s3_url = \"https://correct-s3-url/path/to/home_sales_revised.csv\"\n",
    "\n",
    "# Local file path to save the downloaded CSV file\n",
    "local_csv_file = \"C:/Users/adity/Downloads/home_sales_revised.csv\"\n",
    "\n",
    "# Downloading the file from S3 with error handling\n",
    "try:\n",
    "    response = requests.get(s3_url)\n",
    "    response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "    with open(local_csv_file, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "except requests.exceptions.HTTPError as errh:\n",
    "    print(f\"Http Error: {errh}\")\n",
    "except requests.exceptions.ConnectionError as errc:\n",
    "    print(f\"Error Connecting: {errc}\")\n",
    "except requests.exceptions.Timeout as errt:\n",
    "    print(f\"Timeout Error: {errt}\")\n",
    "except requests.exceptions.RequestException as err:\n",
    "    print(f\"OOps: Something Else: {err}\")\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark_session = SparkSession.builder.appName(\"SparkSQLExample\").getOrCreate()\n",
    "\n",
    "# Reading the local CSV file into a DataFrame\n",
    "df_home_sales = spark_session.read.csv(\"file:///\" + local_csv_file, header=True, inferSchema=True)\n",
    "df_home_sales.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RoljcJ7WPpnm"
   },
   "outputs": [],
   "source": [
    "\n",
    "if 'df_home_sales' in locals() and not df_home_sales.rdd.isEmpty():\n",
    "    df_home_sales.createOrReplaceTempView('home_sales_view')\n",
    "else:\n",
    "    print('DataFrame not loaded correctly or is empty!')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6fkwOeOmqvq",
    "outputId": "bdded620-79c4-488d-c7a5-91c6799c419e"
   },
   "outputs": [],
   "source": [
    "# Example Query to calculate average price of 4 bedroom houses sold each year\n",
    "query_avg_price_4_bedrooms = \"\"\"\n",
    "SELECT YEAR(date) AS Year,\n",
    "       ROUND(AVG(price), 2) AS Average_Price\n",
    "FROM home_sales_view\n",
    "WHERE bedrooms = 4\n",
    "GROUP BY Year\n",
    "ORDER BY Year DESC\n",
    "\"\"\"\n",
    "result = spark_session.sql(query_avg_price_4_bedrooms)\n",
    "result.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8p_tUS8h8it",
    "outputId": "65806e5f-6262-41c0-ff65-5107464e5c4d"
   },
   "outputs": [],
   "source": [
    "# Query for average price of homes with 3 bedrooms and 3 bathrooms per year built\n",
    "query_avg_price_3_bed_3_bath = \"\"\"\n",
    "SELECT date_built AS Year_Built,\n",
    "       ROUND(AVG(price), 2) AS Average_Price\n",
    "FROM home_sales_view\n",
    "WHERE bedrooms = 3 AND bathrooms = 3\n",
    "GROUP BY Year_Built\n",
    "ORDER BY Year_Built DESC\n",
    "\"\"\"\n",
    "spark_session.sql(query_avg_price_3_bed_3_bath).show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-Eytz64liDU",
    "outputId": "17119810-56ad-40c3-de5e-c3db57e43bcc"
   },
   "outputs": [],
   "source": [
    "# Query for average price of specific homes per year built\n",
    "query_specific_homes = \"\"\"\n",
    "SELECT date_built AS Year_Built,\n",
    "       ROUND(AVG(price), 2) AS Average_Price\n",
    "FROM home_sales_view\n",
    "WHERE bedrooms = 3 AND bathrooms = 3 AND sqft_living >= 2000 AND floors = 2\n",
    "GROUP BY Year_Built\n",
    "ORDER BY Year_Built DESC\n",
    "\"\"\"\n",
    "spark_session.sql(query_specific_homes).show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUrfgOX1pCRd",
    "outputId": "17c25774-855e-4290-a4bd-a04902bdc13a"
   },
   "outputs": [],
   "source": [
    "# Query for average price and view rating of homes\n",
    "import time\n",
    "start_time_query = time.time()\n",
    "query_avg_price_view = \"\"\"\n",
    "SELECT view, \n",
    "       ROUND(AVG(price), 2) AS Average_Price\n",
    "FROM home_sales_view\n",
    "GROUP BY view\n",
    "HAVING AVG(price) >= 350000\n",
    "ORDER BY view DESC\n",
    "\"\"\"\n",
    "spark_session.sql(query_avg_price_view).show()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time_query))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAhk3ZD2tFy8",
    "outputId": "0a8f132d-40a8-4bd4-b5f2-2847e98427f5"
   },
   "outputs": [],
   "source": [
    "# Caching the temporary table and checking if it's cached\n",
    "spark_session.sql('CACHE TABLE home_sales_view')\n",
    "is_cached = spark_session.catalog.isCached('home_sales_view')\n",
    "print(\"Is home_sales_view cached? \", is_cached)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4opVhbvxtL-i",
    "outputId": "38ec8487-795f-4550-b50c-fcc6f2b7c769"
   },
   "outputs": [],
   "source": [
    "# Check if the table is cached.\n",
    "is_cached = spark_session.catalog.isCached('home_sales_view')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5GnL46lwTSEk",
    "outputId": "09a16c73-194d-4371-95d1-ee64fe83b91c"
   },
   "outputs": [],
   "source": [
    "# Using the cached data for the view ratings query\n",
    "start_time_cached = time.time()\n",
    "\n",
    "query_view_ratings_cached = \"\"\"\n",
    "SELECT view, \n",
    "       ROUND(AVG(price), 2) AS Average_Price\n",
    "FROM home_sales_view\n",
    "GROUP BY view\n",
    "HAVING AVG(price) >= 350000\n",
    "ORDER BY view DESC\n",
    "\"\"\"\n",
    "spark_session.sql(query_view_ratings_cached).show()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time_cached))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qm12WN9isHBR"
   },
   "outputs": [],
   "source": [
    "# Ensure you have the DataFrame df_home_sales loaded at this point\n",
    "# Writing the DataFrame to partitioned Parquet format\n",
    "output_parquet_path = \"C:/Users/adity/Downloads/partitioned_home_sales\"\n",
    "\n",
    "try:\n",
    "    df_home_sales.write.partitionBy(\"date_built\").mode(\"overwrite\").parquet(output_parquet_path)\n",
    "    print(\"DataFrame successfully written to partitioned Parquet format.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZ7BgY61sRqY"
   },
   "outputs": [],
   "source": [
    "# Reading the partitioned Parquet data\n",
    "try:\n",
    "    df_partitioned_home_sales = spark_session.read.parquet(output_parquet_path)\n",
    "    print(\"Successfully read from partitioned Parquet format.\")\n",
    "    df_partitioned_home_sales.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while reading Parquet data: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6MJkHfvVcvh"
   },
   "outputs": [],
   "source": [
    "# Adjust the path to where your partitioned Parquet files are stored\n",
    "parquet_path = \"C:/path_to_partitioned_parquet_data\"\n",
    "\n",
    "# Read the partitioned Parquet data into a DataFrame\n",
    "try:\n",
    "    df_partitioned_home_sales = spark_session.read.parquet(parquet_path)\n",
    "    print(\"Partitioned Parquet data loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Parquet data: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_Vhb52rU1Sn",
    "outputId": "a0b8d0c4-55ed-4c6c-bfd8-4c8c5334838e"
   },
   "outputs": [],
   "source": [
    "# Create or replace a temporary view using the DataFrame\n",
    "try:\n",
    "    df_partitioned_home_sales.createOrReplaceTempView(\"partitioned_home_sales_view\")\n",
    "    print(\"Temporary view created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating temporary view: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjjYzQGjtbq8",
    "outputId": "830549fd-bb41-451b-9183-5ebf6e3e470b"
   },
   "outputs": [],
   "source": [
    "# Example query on the temporary view\n",
    "try:\n",
    "    result = spark_session.sql(\"\"\"\n",
    "        SELECT some_column, COUNT(*)\n",
    "        FROM partitioned_home_sales_view\n",
    "        GROUP BY some_column\n",
    "    \"\"\")\n",
    "    result.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error executing query: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sy9NBvO7tlmm",
    "outputId": "be73e0e3-5e85-4794-aad9-025fb6fa84a7"
   },
   "outputs": [],
   "source": [
    "# Uncaching the temporary table\n",
    "try:\n",
    "    # Check if the table is cached\n",
    "    if spark_session.catalog.isCached(\"partitioned_home_sales_view\"):\n",
    "        spark_session.sql(\"UNCACHE TABLE partitioned_home_sales_view\")\n",
    "        print(\"Temporary view uncached successfully.\")\n",
    "    else:\n",
    "        print(\"Temporary view is not cached.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error uncaching temporary view: {e}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Home_Sales_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
